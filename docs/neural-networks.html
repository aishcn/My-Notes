<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 4 Neural Networks | Anjali’s Notes</title>
<meta name="author" content="Anjali Chauhan">
<meta name="description" content="Concepts covered in CPSC 330, CPSC 340, ECON 323 and beyond.">
<meta name="generator" content="bookdown 0.26 with bs4_book()">
<meta property="og:title" content="Chapter 4 Neural Networks | Anjali’s Notes">
<meta property="og:type" content="book">
<meta property="og:description" content="Concepts covered in CPSC 330, CPSC 340, ECON 323 and beyond.">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 4 Neural Networks | Anjali’s Notes">
<meta name="twitter:description" content="Concepts covered in CPSC 330, CPSC 340, ECON 323 and beyond.">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Anjali’s Notes</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> Anjali’s Notes</a></li>
<li><a class="" href="statistics.html"><span class="header-section-number">2</span> Statistics</a></li>
<li><a class="" href="machine-learning.html"><span class="header-section-number">3</span> Machine Learning</a></li>
<li><a class="active" href="neural-networks.html"><span class="header-section-number">4</span> Neural Networks</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="neural-networks" class="section level1" number="4">
<h1>
<span class="header-section-number">4</span> Neural Networks<a class="anchor" aria-label="anchor" href="#neural-networks"><i class="fas fa-link"></i></a>
</h1>
<!-- ## Briefly explain how a basic neural network works -->
<!-- At its core, a Neural Network is essentially a network of mathematical equations. It takes one or more input variables, and by going through a network of equations, results in one or more output variables. -->
<!-- In a neural network, there’s an input layer, one or more hidden layers, and an output layer. The input layer consists of one or more feature variables (or input variables or independent variables) denoted as x1, x2, …, xn. The hidden layer consists of one or more hidden nodes or hidden units. A node is simply one of the circles in the diagram above. Similarly, the output variable consists of one or more output units. -->
<!-- Like I said at the beginning, a neural network is nothing more than a network of equations. Each node in a neural network is composed of two functions, a linear function and an activation function. This is where things can get a little confusing, but for now, think of the linear function as some line of best fit. Also, think of the activation function like a light switch, which results in a number between 1 or 0. -->
<!-- ## Activation Functions -->
<!-- An activation function is like a light switch — it determines whether a neuron should be activated or not. -->
<!-- There are several types of activation functions, but the most popular activation function is the Rectified Linear Unit function, also known as the ReLU function.  -->
<!-- ### What is the role of the activation function? -->
<!-- The purpose of the activation function is to introduce non-linearity into the output of a neuron. The activation function decides whether a neuron should be activated or not by calculating weighted sum and further adding bias with it. -->
<!-- ### Why Tanh activation function preferred over sigmoid? -->
<!-- Tanh function is called a shifted version of the sigmoid function. The output of Tanh centers around 0 and sigmoid’s around 0.5. Tanh Convergence is usually faster if the average of each input variable over the training set is close to zero. -->
<!-- When you struggle to quickly find the local or global minimum, in such case Tanh can be helpful in faster convergence. The derivatives of Tanh are larger than Sigmoid that causes faster optimization of the cost function. Tanh and Sigmoid both suffered from vanishing gradient problems. -->
<!-- ### Why is the ReLU activation function is better than the sigmoid activation function? -->
<!-- Sigmoid function bounded between 0 and 1. It is differentiable, non-linear, and produces non-binary activations. But the problem with Sigmoid is the vanishing gradients. -->
<!-- ReLu(Rectified Linear Unit) is like a linearity switch. If you don’t need it, you “switch” it off. If you need it, you “switch” it on. ReLu avoids the problem of vanishing gradient. -->
<!-- ReLu also provides the benefit of sparsity and sigmoids result in dense representations. Sparse representations are more useful than dense representations. -->
<!-- ### What is the use of the leaky ReLU function? -->
<!-- The main problem with ReLU is, it is not differentiable at 0 and may result in exploding gradients. To resolve this problem Leaky ReLu was introduced that is differentiable at 0. It provides small negative values when input is less than 0. -->
<!-- ## What is the “dying ReLU” problem in neural networks? -->
<!-- When ReLu provides output zero for any input(large negative biases). This problem will occur due to a high learning rate and large negative bias. Leaky ReLU is a commonly used method to overcome a dying ReLU problem. It adds a small negative slope to prevent the dying ReLU problem. -->
<!-- ## Why is Rectified Linear Unit a good activation function? -->
<!-- The Rectified Linear Unit, also known as the ReLU function, is known to be a better activation function than the sigmoid function and the tanh function because it performs gradient descent faster. Notice in the image to the left that when x (or z) is very large, the slope is very small, which slows gradient descent significantly. This, however, is not the case for the ReLU function. -->
<!-- ## What is the activation function? Why do we need them? -->
<!-- Activation functions are mathematical functions that transform the output of a neural network on a certain scale. It means it normalizes the output between range 0 and 1 or -1 and 1. Activation functions in neural networks introduce non-linearity. It helps neural networks to handle non-linear relationships. -->
<!-- ## What is backward and forward propagation? -->
<!-- Backpropagation traverses in the reverse direction. It computes the gradient(or delta rule) of parameters(weights and biases) in order to map the output layer to the input layer. The main objective of backpropagation is to minimize the error. This process will repeat until the error is minimized and final parameters will be used for producing the output. -->
<!-- Forward propagation or forward pass computes the intermediate values in order to map the input and output layer. -->
<!-- ## What is backpropagation in neural networks in a pure mathematical sense? -->
<!-- So backpropagation in Computer science is the algorithmic way in which we send the result of some computation back to the parent recursively. -->
<!-- In Machine learning, backpropagation sends feedback to the neural net. -->
<!-- The complete algorithm for this is known as Gradient Descent. The part of Gradient Descent(or similar algorithms) where you infer the error(usually with calculus) and correct it is known as Backpropagation. -->
<!-- So any training step includes calculating the gradient(differentiation in calculus) and then doing backpropagation(integrating the gradient to get back the way the weights should change). -->
<!-- ## Cost Function -->
<!-- A cost function for a neural network is similar to a cost function that you would use for any other machine learning model. It’s a measure of how ‘good” a neural network is in regards to the values that it predicts compared to the actual values. The cost function is inversely proportional to the quality of a model — the better the model, the lower the cost function and vice versa. -->
<!-- The purpose of a cost function is so that you have value to optimize. By minimizing the cost function of a neural network, you’ll achieve the optimal weights and parameters of the model, thereby maximizing the performance of it. -->
<!-- There are several commonly used cost functions, including the quadratic cost, cross-entropy cost, exponential cost, Hellinger distance, Kullback-Leibler divergence, etc. -->
<!-- The main objective of the neural network is to find the optimal set of weights and biases by minimizing the cost function. Cost function or loss function is a measure used to measure the performance of the neural network on test data set. It measures the ability to estimate the relationship between X and y. An example of cost functions is the mean square error. -->
<!-- ## Backpropagation -->
<!-- Backpropagation is an algorithm that closely ties with the cost function. Specifically, it is an algorithm that is used to compute the gradient of the cost function. It has adopted a lot of popularity and use due to its speed & efficiency compared to other approaches. -->
<!-- Its name stems from the fact that the calculation of the gradient starts with the gradient of the final layer of weights and moves backwards to the gradient of the first layer of weights. Consequently, the error at layer k is dependent on the next layer k+1. -->
<!-- Generally, backpropagation works as follows: -->
<!-- - Calculates the forward phase for each input-output pair -->
<!-- - Calculates the backward phase for each pair -->
<!-- - Combine the individual gradients -->
<!-- - Update the weights based on the learning rate and the total gradient -->
<!-- ## Difference between convex and non-convex cost function; what does it mean when a cost function is non-convex? -->
<!-- A convex function is one where a line drawn between any two points on the graph lies on or above the graph. It has one minimum. -->
<!-- A non-convex function is one where a line drawn between any two points on the graph may intersect other points on the graph. It characterized as “wavy”. -->
<!-- When a cost function is non-convex, it means that there’s a likelihood that the function may find local minima instead of the global minimum, which is typically undesired in machine learning models from an optimization perspective. -->
<!-- ## Convolutional Neural Networks -->
<!-- ### What is CNN? How does CNN work? -->
<!-- CNN is Feedforward neural network. CNN filters the raw image detail patterns and classifies them using a traditional neural network. Convolution focuses on small patches in the image and represents a weighted sum of image pixel values. It offers applications in Image recognition and object detection. It works in the following steps: -->
<!-- - Convolution Operation -->
<!-- - ReLu layer -->
<!-- - Pooling- Max and Min Pool -->
<!-- - Flattening -->
<!-- - Full connection -->
<!-- A Convolutional Neural Network (CNN) is a type of neural network that takes an input (usually an image), assigns importance to different features of the image, and outputs a prediction. What makes CNNs better than feedforward neural networks is that it better captures the spatial (pixel) dependencies throughout the image, meaning it can understand the composition of an image better. -->
<!-- For those who are interested, CNNs use a mathematical operation called convolution. Wikipedia defines convolution as a mathematical operation on two functions that produces a third function expressing how the shape of one is modified by the other. Thus, CNN's use convolution instead of general matrix multiplication in at least one of their layers. -->
<!-- **TLDR**: CNNs are a type of neural network that is mainly used for image classification. -->
<!-- ### What are Convolution layers? -->
<!-- The convolution layer is inspired by the visual cortex. It converts the image into layers, transforms into small images, and extracts features from images. It will sum up the results into a single output pixel. It captures the relationship between pixels and detects edge, blur, and sharpen features. -->
<!-- ## Recurrent Neural Networks -->
<!-- A Recurrent Neural Network (RNNs) is another type of neural network that works exceptionally well with sequential data due to its ability to ingest inputs of varying sizes. RNNs consider both the current input as well as previous inputs it was given, which means that the same input can technically produce a different output based on the previous inputs given. -->
<!-- Technically speaking, RNNs are a type of neural network where connections between the nodes form a digraph along a temporal sequence, allowing them to use their internal memory to process variable-length sequences of inputs. -->
<!-- **TLDR**: RNNs are a type of neural network that is mainly used for sequential or time-series data. -->
<!-- Recurrent neural networks, also known as RNNs, are a class of neural networks that allow previous outputs to be used as inputs while having hidden states. -->
<!-- They are commonly used to recognize the pattern of sequences in data, including time-series data, stock market data, etc. -->
<!-- ## Long Short-Term Memory Networks -->
<!-- Long Short-Term Memory (LSTM) networks are a type of Recurrent Neural Networks that addresses one of the shortfalls of regular RNNs: RNNs have short-term memory. -->
<!-- Specifically, if a sequence is too long, i.e. if there is a lag greater than 5–10 steps, RNNs tend to dismiss information that was provided in the earlier steps. For example, if we fed a paragraph into an RNN, it may overlook information provided at the beginning of the paragraph. -->
<!-- Thus LSTMs were created to resolve this issue. -->
<!-- ## Weight Initialization -->
<!-- The point of weight initialization is to make sure that a neural network doesn’t converge to a trivial solution. -->
<!-- If the weights are all initialized to the same value(eg. equal to zero) then each unit will get exactly the same signal and every layer would behave as if it were a single cell. -->
<!-- Therefore, you want to randomly initialize the weights near zero, but not equal to zero. This is an expectation of the stochastic optimization algorithm that’s used to train the model. -->
<!-- ### How are weights initialized in a Network? -->
<!-- The weights of a neural network MUST be initialized randomly because this is an expectation of stochastic gradient descent. -->
<!-- If you initialized all weights to the same value (i.e. zero or one), then each hidden unit will get exactly the same signal. For example, if all weights are initialized to 0, all hidden units will get zero signal. -->
<!-- ## Batch vs. Stochastic Gradient Descent -->
<!-- Batch gradient descent and stochastic gradient descent are two different methods used to compute the gradient. -->
<!-- Batch gradient descent simply computes the gradient using the whole dataset. It is much slower especially with larger datasets but is better for convex or smooth error manifolds. -->
<!-- With stochastic gradient descent, the gradient is computed using a single training sample at a time. Because of this, it is computationally faster and less expensive. Consequently, however, when a global optimum is reached, it tends to bounce around — this results in a good solution but not an optimal solution. -->
<!-- ## Hyper-parameters -->
<!-- Hyper-parameters are the variables that regulate the network structure and the variables which govern how the network is trained. Common hyper-parameters include the following: -->
<!-- - Model architecture parameters such as the number of layers, number of hidden units, etc. -->
<!-- - The learning rate (alpha) -->
<!-- - Network weight initialization -->
<!-- - Number of epochs (defined as one cycle through the whole training dataset) -->
<!-- - Batch size -->
<!-- - and more. -->
<!-- ## Learning Rate -->
<!-- The learning rate is a hyper-parameter used in neural networks that control how much to adjust the model in response to the estimated error each time the model weights are updated. -->
<!-- If the learning rate is too low, your model will train very slowly as minimal updates are made to the weights through each iteration. Thus, it would take many updates before reaching the minimum point. -->
<!-- If the learning rate is set too high, this causes undesirable divergent behavior to the loss function due to drastic updates in weights, and it may fail to converge. -->
<!-- ## What is Deep Learning? -->
<!-- Deep Learning is a subdomain of Machine Learning. In deep learning, a large number of layers in the architecture. These successive layers learn more complex patterns in the data. Deep Learning offers various applications in text, voice, image, and video data. -->
<!-- ## What is Gradient Descent? How does it work? -->
<!-- It is a first-order iterative optimization technique for finding the minimum of a function. It is an efficient optimization technique to find a local or global minimum. -->
<!-- In gradient descent, gradient and step are taken at each point. It takes the current value of parameters and updates it with the help of gradient and step width. the gradient is recomputed again and steps decremented in each iteration. This process continues until the convergence achieved. -->
<!-- Types of Gradient Descent -->
<!-- - Full batch gradient descent uses a full dataset. -->
<!-- - Stochastic gradient descent uses a sample of the dataset. -->
<!-- ### Stochastic Gradient Descent -->
<!-- Stochastic Gradient Descent builds on top of Gradient Descent where it can work with complicated Cost Functions. -->
<!-- ### Gradient Descent Stuck in Local Minima and Misses True Minima.  -->
<!-- The Gradient Descent works well only in case of convex cost functions with one minimum only. However, in the case of complicated Cost Functions, the Gradient Descent can easily get stuck in local minima which ruins your Neural Network learning. -->
<!-- ### Stochastic vs. Gradient Descent -->
<!-- To understand how Stochastic is different from Gradient Descent let’s take an example. We will assume you have labeled data as rows and you’re inputting them into your Neural Network for training. -->
<!-- ## What is the difference between model parameters and hyperparameters? -->
<!-- Model parameters are internal and can be estimated from data. Model hyperparameters are external to the model and can not be estimated from data. -->
<!-- ## What do you mean by Dropout and Batch Normalization? -->
<!-- Dropout is a technique for normalization. It drops out or deactivates some neurons from the neural network to remove the problem of overfitting. In other words, it introduces the noise in the neural network so that model is capable to generalize the model. -->
<!-- Normalization is used to reduce the algorithm time that spends on the oscillation on different values. It brings all the features on the same input scale. -->
<!-- Batch Normalization is also normalizing the values but at hidden states on small batches of data. The research has shown that removing Dropout with Batch Normalization improves the learning rate without loss in generalization. -->
<!-- ## What is vanishing gradient descent? -->
<!-- RNN follows the chain rule in its backpropagation. When one of the gradients approaches zero then all the gradient will move towards zero. This small value is not sufficient for training the model. Here, a small gradient means that weights and biases of the neural network will not be updated effectively. -->
<!-- Also, at hidden layers activation functions such as sigmoid function and Tanh causes small derivatives that decrease the gradient. -->
<!-- The solution to Vanishing Gradient Descent -->
<!-- - Use a different activation function such as ReLu(Rectified Linear Unit). -->
<!-- - Batch normalization can also solve this problem by simply normalizing the input space. -->
<!-- - Weight initialization -->
<!-- - LSTM -->
<!-- ## What is exploding gradient descent? -->
<!-- Exploding gradient is just an opposite situation of vanishing gradient. A too-large value of RNN causes powerful training. We can overcome this problem by using Truncated Backpropagation, penalties, Gradient Clipping. -->
<!-- Gradient is the direction and magnitude calculated during training of a neural network that is used to update the network weights in the right direction and by the right amount. -->
<!-- “Exploding gradients are a problem where large error gradients accumulate and result in very large updates to neural network model weights during training.” At an extreme, the values of weights can become so large as to overflow and result in NaN values. -->
<!-- This has the effect of your model being unstable and unable to learn from your training data.  -->
<!-- ## What is LSTM and BiLSTM? -->
<!-- LSTM is a special type of RNN. It also uses a chain-like structure but it has the capability to learn and remember long-term sequences. LSTM handles the issue of vanishing gradient. It keeps gradient step enough and therefore the short training and the high accuracy. It uses gated cells to write, read, erase the value. It has three gates: input, forget, and output gate. -->
<!-- BiLSTM learns sequential long terms in both directions. It captures the information from both the previous and next states. Finally, it merges the results of two states and produces output. It memorizes information about a sentence from both directions. -->
<!-- ## Explain gates used in LSTM with their functions. -->
<!-- LSTM has three gates: input, forget, and output gate. The input gate is used to add the information to the network, forget used to discard the information, and the output gate decides which information pass to the hidden and output layer. -->
<!-- ## What is the difference between LSTM and GRU? -->
<!-- GRU is also a type of RNN. It is slightly different from LSTM. The main difference between LSTM and GRU Gates is the number of gates. -->
<!-- - LSTM uses three gates(input, forget, and output gate) while GRU uses two gates(reset and update). -->
<!-- - In GRU, the update gate is similar to the input and forget gate of LSTM and the reset gate is another gate used to decide how much past information to forget. -->
<!-- - GRU is faster compared to LSTM. -->
<!-- - GRU needs fewer data to generalize. -->
<!-- ## What is padding? -->
<!-- Sometimes filter unable to fit the input image perfectly. We have two strategies for padding: Zero padding and valid padding. Zero paddings add zero so that the image filter fits the image. Valid padding drops the part of the image. (Drop the part of the image) -->
<!-- ## What are pooling and Flattening? -->
<!-- Pooling is used to reduce the spatial size and selects the important pixel values as features. It is also known as Downsampling. It also makes faster computation by reducing its dimension. Pooling summarizes the sub-region and captures rotational and positional invariant features. -->
<!-- **Pooling**: There are several pooling operations but the most common is max pooling. It teaches the network spatial variance, in simple words the ability to recognize the image features even if the image is upside down, tilted, the image is taken from far or close, etc. The output of this operation is a pooled feature map. -->
<!-- **Flattening**: The purpose of this operation is to be able to input the pooled feature map into the neural network. -->
<!-- The below image shows the entire CNN operation. -->
<!-- ## What is Epoch, Batch, and Iteration in Deep Learning? -->
<!-- - Epoch is a one-pass to the entire dataset. Here, one pass = one forward pass + one backward pass -->
<!-- - Batch size is the number of training examples in one forward/backward pass. The larger batch size requires more memory space. -->
<!-- - Iteration is the number of passes. If each pass using batch size then the number of times a batch of data passed through the algorithm. -->
<!-- - For example, if you have 1000 training examples, and your batch size is 200, then it will take 5 iterations to complete 1 epoch. -->
<!-- ## What is an Auto-encoder? -->
<!-- Autoencoders are unsupervised deep learning techniques that reduce the dimension of data to encode. Autoencoders encoded the data on one side and decoded it on another side. After encoding, it transforms data into a reduced representation called code or embedding(also known as latent-space representation). This embedding then transformed into the output. Autoencoders can do dimensionality reduction and improve the performance of the algorithm. -->
<!-- ## What do you understand by Boltzmann Machine and Restricted Boltzmann Machines? -->
<!-- Boltzmann machines are stochastic(non-deterministic models) and generative neural networks. It has the capability to discover interesting features that represent complex patterns in the data. Boltzmann Machine uses many layers for feature detectors that make it a slower network. Restricted Boltzmann Machines (RBMs) have a single layer of feature detectors that makes them faster compared to Boltzmann Machine. -->
<!-- RBM is a neural network model are also known as Energy-Based Models. RBM offers various applications in recommender systems, classification, regression, topic modeling, and dimensionality reduction. -->
<!-- ## Explain Generative Adversarial Network. -->
<!-- GAN (Generative Adversarial Network) is unsupervised deep learning that trains two networks at the same time. It has two components: Generator and Discriminator. The generator generates the images close to the real image and the discriminator determines the difference between fake and real images. GAN is able to produce new content. -->
<!-- ## What is Adam? What’s the main difference between Adam and SGD?  -->
<!-- Adam (Adaptive Moment Estimation) is a optimization technique for training neural networks. on an average, it is the best optimizer .It works with momentums of first and second order. The intuition behind the Adam is that we don’t want to roll so fast just because we can jump over the minimum, we want to decrease the velocity a little bit for a careful search. -->
<!-- Adam tends to converge faster, while SGD often converges to more optimal solutions. SGD's high variance disadvantages gets rectified by Adam (as advantage for Adam). -->
<!-- ## When would you use Adam and when SGD?  -->
<!-- Adam tends to converge faster, while SGD often converges to more optimal solutions. -->
<!-- ## Neural Network: How Do They Learn -->
<!-- The learning happens by passing labeled data all the way from the input layers to the output layers then all the way back. Since the data is labeled the Neural network knows what's the expected output and compares it to the actual output of the Neural Network. -->
<!-- In the first Epoch, the labeled data is entered at the input layer and propagated to the output layer where your Neural Network will calculate an output. The difference between the actual output of your Neural Network vs. the expected output is called the Cost Function. The goal of your Neural Network is to decrease this Cost Function as much as possible. So, your Neural Network will Back-Propagate from the output layer all the way to the input layer and update the weights of the Neurons accordingly in an attempt to minimize this Cost Function. -->
<!-- The act of sending the data from the input layer to the output layer then all the way back is called an Epoch. In each epoch, the Neural Network updates the weights of the Neurons which is also known as Learning. After multiple Epochs and weight updates, the loss function (the difference between Neural Network output vs. Actual output) should reach a minimum. -->
<!-- ## Neural Network during Learning Phase -->
<!-- Upon learning, the Neurons will have different weights and those weights will dictate future outputs. For example in our earlier car vs. bus classification scenario a Neuron could be looking at the number of windows to decide if the object is a car or bus, obviously, this Neuron will have higher weight than a Neuron looking at the color of the object to determine if it’s a car or a bus. This is an oversimplification of the Neurons function but I want you to get the idea of Neuron weights according to importance. -->
<!-- ## Gradient Descent -->
<!-- Gradient Descent is a method to minimize the Cost Function in order to update the Neurons weights. This method tells your Neural Network how to calculate the Cost Function in a fast efficient manner to minimize the difference between the actual and expected outputs. -->
<!-- The easiest to understand and most common example is comparing your Cost Function to a ball trying to find the lowest point by updating its slope. -->
<!-- Gradient (Batch) Descent when your Neural Network goes through the data one row at a time and calculate the actual output for each row. Then after finishing all rows in your dataset, the Neural Network compares the cumulative total output of all rows to the expected output and backpropagates to update the weights. This means the Neural Network updates the weights once after working through the entire dataset as one big batch, That’s a big timely Epoch. The Neural Network will do this several times to train the network. -->
<!-- Stochastic Gradient Descent when your Neural Network goes through the data one row at a time and calculate the actual output for each row. Right away the Neural Network compares the actual output of the first row to the expected output and backpropagates to update the weights, that completes an Epoch. Then the same happens for the second row, comparing outputs and backpropagating to update weights. All the way to the last row, so multiple Epochs and multiple weight updating happen to go through the entire dataset rather than treating it as one big batch like in the case of Gradient Descent. This helps to avoid local minimums and it’s faster than Gradient Descent cause it doesn't need to load all data in memory and run through them at once rather it loads one row at a time and updates weights. -->
<!-- There is the best of both worlds method that’s called mini-batch Gradient Descent which is basically combining both. You decide how many rows to run and update at once. So instead of running the whole dataset as one batch or instead of running one row at a time, you have the flexibility to choose any number of rows to run. -->
<!-- ## Back-Propagation -->
<!-- By now you should know what back-propagation is if you don’t then it’s simply adjusting the weights of all the Neurons in your Neural Network after calculating the Cost Function. Back-Propagation is how your Neural Network learns and its the result of calculating the Cost Function. The important concept to know is that Back-Propagation updates all the weights of all the Neurons simultaneously. -->
<!-- For training purposes, in the beginning, the weights of the Neurons are randomly initialized with small numbers then through learning and back-propagation the weights start to get updated with meaningful values. -->
<!-- ## Softmax Function -->
<!-- This is mainly used in classification problems for multi-class predictions. It is typically in the output layer of the Neural Network. -->
<!-- You could apply different activation functions for hidden layers and output layers. In this diagram, ReLU is applied for hidden layers while Sigmoid is applied for the output layer. This is common to predict the probability of something. -->
<!-- ## What happens if the learning rate is set too high or too low? -->
<!-- If the learning rate is too low, your model will train very slowly as minimal updates are made to the weights through each iteration. Thus, it would take many updates before reaching the minimum point. -->
<!-- If the learning rate is set too high, this causes undesirable divergent behavior to the loss function due to drastic updates in weights, and it may fail to converge. -->

</div>
  <div class="chapter-nav">
<div class="prev"><a href="machine-learning.html"><span class="header-section-number">3</span> Machine Learning</a></div>
<div class="next"><a href="references.html">References</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav"><li><a class="nav-link" href="#neural-networks"><span class="header-section-number">4</span> Neural Networks</a></li></ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Anjali’s Notes</strong>" was written by Anjali Chauhan. It was last built on 2022-05-06.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer>
</body>
</html>
