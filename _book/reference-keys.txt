machine-learning-prep-guide
probability
conditional-probability
law-of-total-probability
counting
random-variables
joint-marginal-and-conditional-probability-distributions
probability-distributions
discrete-probability-distributions
continuous-probability-distributions
markov-chains
probability-interview-questions
easy
medium
hard
statistics
properties-of-random-variables
law-of-large-numbers
central-limit-theorem
hypothesis-testing
general-setup
test-statistics
z-test
t-test
chi-squared-test
hypothesis-testing-for-population-proportions
p-values-and-confidence-intervals
type-i-and-ii-errors
statistics-interview-questions
easy-1
medium-1
hard-1
machine-learning
linear-algebra
gradient-descent
model-evaluation-and-selection
bias-variance-trade-off
model-complexity-and-overfitting
regularization
interpretability-explainability
model-training
cross-validation
boostrapping-and-bagging
hyperparameter-tuning
training-times-and-learning-curves
linear-regression
evaluating-linear-regression
subset-selection
linear-regression-assumptions
avoiding-linear-regression-pitfalls
heteroscedasticity
normality
outliers
multicollinearity
confounding-variabes
generalized-linear-models
classification
general-framework
evaluating-classifiers
building-and-interpreting-a-confusion-matrix
precision-and-recall
visualizing-classifier-performance
logistic-regression
naive-bayes
svms
decision-trees
training
entropy
random-forests
boosting
dimensionality-reduction
principal-component-analysis
clustering
k-means-clustering
k-means-alternatives
gaussian-mixture-model-gmm
neural-networks
perceptron
backpropagation
training-neural-networks
general-framework-1
training-optimization-techniques
transfer-learning
addressing-overfitting
types-of-neural-networks
cnns
rnns
lstms
reinforcement-learning
end-to-end-ml-workflow
step-1-clarify-the-problem-and-constraints
step-2-establish-metrics
step-3-understand-your-data-sources
step-4-explore-your-data
step-5-clean-your-data
step-6-feature-engineering
step-7-model-selection
step-8-model-training-evaluation
step-9-deployment
machine-learning-interview-questions
easy-2
medium-2
hard-2
metrics
accuracy
precision
recall
f1-score
which-metrics-to-use-when-classification
accuracy-1
precision-1
recall-1
f1-score-1
precision-recall-tradeoff
log-lossbinary-crossentropy
categorical-cross-entropy
auc
roc-curve
what-is-the-difference-between-precision-and-recall
precision-recall-trade-off
what-is-the-roc-curve-when-to-use-it
what-is-auc-au-roc-when-to-use-it
we-have-two-models-one-with-85-accuracy-one-82.-which-one-do-you-pick
is-accuracy-always-a-good-metric
what-is-a-confusion-matrix
how-to-check-if-the-regression-model-fits-the-data-well
model-evaluation
metrics-1
accuracy-2
precision-2
recall-2
f1-score-2
which-metrics-to-use-when-classification-1
accuracy-3
precision-3
recall-3
f1-score-3
precision-recall-tradeoff-1
log-lossbinary-crossentropy-1
categorical-cross-entropy-1
auc-1
roc-curve-1
what-is-the-difference-between-precision-and-recall-1
precision-recall-trade-off-1
what-is-the-roc-curve-when-to-use-it-1
what-is-auc-au-roc-when-to-use-it-1
we-have-two-models-one-with-85-accuracy-one-82.-which-one-do-you-pick-1
is-accuracy-always-a-good-metric-1
what-is-a-confusion-matrix-1
how-to-check-if-the-regression-model-fits-the-data-well-1
model-evaluation-1
metrics-2
accuracy-4
precision-4
recall-4
f1-score-4
which-metrics-to-use-when-classification-2
accuracy-5
precision-5
recall-5
f1-score-5
precision-recall-tradeoff-2
log-lossbinary-crossentropy-2
categorical-cross-entropy-2
auc-2
roc-curve-2
what-is-the-difference-between-precision-and-recall-2
precision-recall-trade-off-2
what-is-the-roc-curve-when-to-use-it-2
what-is-auc-au-roc-when-to-use-it-2
we-have-two-models-one-with-85-accuracy-one-82.-which-one-do-you-pick-2
is-accuracy-always-a-good-metric-2
what-is-a-confusion-matrix-2
how-to-check-if-the-regression-model-fits-the-data-well-2
model-evaluation-2
metrics-3
accuracy-6
precision-6
recall-6
f1-score-6
which-metrics-to-use-when-classification-3
accuracy-7
precision-7
recall-7
f1-score-7
precision-recall-tradeoff-3
log-lossbinary-crossentropy-3
categorical-cross-entropy-3
auc-3
roc-curve-3
what-is-the-difference-between-precision-and-recall-3
precision-recall-trade-off-3
what-is-the-roc-curve-when-to-use-it-3
what-is-auc-au-roc-when-to-use-it-3
we-have-two-models-one-with-85-accuracy-one-82.-which-one-do-you-pick-3
is-accuracy-always-a-good-metric-3
what-is-a-confusion-matrix-3
how-to-check-if-the-regression-model-fits-the-data-well-3
model-evaluation-3
intro
linear-regression-1
whats-the-difference-between-linear-regression-and-logistic-regression
what-is-overfitting
what-is-the-bias-variance-tradeoff
what-are-ridge-and-lasso-regression-and-what-are-the-differences-between-them
whats-the-difference-between-l2-and-l1-regularization
whats-regularization-and-whats-the-difference-between-l1-and-l2-regularization
ridge-regression
lasso-regression
can-we-use-l1-regularization-for-feature-selection
when-do-we-need-to-perform-feature-normalization-for-linear-models-when-its-okay-not-to-do-it
logistic-regression-1
what-is-logistic-regression-or-state-an-example-when-you-have-used-logistic-regression-recently.
metrics-4
accuracy-8
precision-8
recall-8
f1-score-8
which-metrics-to-use-when-classification-4
accuracy-9
precision-9
recall-9
f1-score-9
precision-recall-tradeoff-4
log-lossbinary-crossentropy-4
categorical-cross-entropy-4
auc-4
roc-curve-4
what-is-the-difference-between-precision-and-recall-4
precision-recall-trade-off-4
what-is-the-roc-curve-when-to-use-it-4
what-is-auc-au-roc-when-to-use-it-4
we-have-two-models-one-with-85-accuracy-one-82.-which-one-do-you-pick-4
is-accuracy-always-a-good-metric-4
what-is-a-confusion-matrix-4
how-to-check-if-the-regression-model-fits-the-data-well-4
model-evaluation-4
clustering-1
math-example
data-preprocessing
what-do-you-mean-by-feature-splitting
what-are-the-feature-selection-methods-used-to-select-the-right-variables
how-do-you-select-the-important-features-while-working-on-a-dataset
what-are-some-of-the-steps-for-data-wrangling-and-data-cleaning-before-applying-machine-learning-algorithms
what-are-the-missing-values-how-do-you-handle-missing-values
name-two-useful-methods-of-pandas-that-are-useful-to-handle-the-missing-values.
give-several-ways-to-deal-with-missing-values
explain-one-hot-encoding-and-label-encoding.-does-the-dimensionality-of-the-dataset-increase-or-decrease-after-applying-these-techniques
why-do-we-need-one-hot-encoding
how-can-you-determine-which-features-are-the-most-important-in-your-model
how-can-you-choose-a-classifier-based-on-training-set-size
is-it-good-to-perform-scaling-before-the-split-or-after-the-split-by-keeping-train-and-test-split-criteria-in-mind
when-can-a-categorical-value-be-treated-as-a-continuous-variable-and-what-effect-does-it-have-when-done-so
if-we-have-a-date-column-in-our-dataset-then-how-will-you-perform-feature-engineering
how-would-you-handle-an-imbalanced-dataset
how-should-you-deal-with-unbalanced-binary-classification
which-technique-would-you-use-in-cases-where-the-number-of-variables-is-greater-than-the-number-of-observations-in-the-dataset.-explain
what-are-3-data-preprocessing-techniques-to-handle-outliers
how-do-we-handle-categorical-variables-in-decision-trees
for-a-classification-problem-how-will-you-know-which-machine-learning-algorithm-to-choose
how-much-data-will-you-allocate-for-your-training-validation-and-test-sets
in-unsupervised-learning-if-a-ground-truth-about-a-dataset-is-unknown-how-can-we-determine-the-most-useful-number-of-clusters-to-be
without-knowing-the-ground-truth-of-a-dataset-then-how-do-we-know-what-the-optimal-number-of-data-clusters-are
the-elbow-method
the-silhouette-method
when-should-you-use-classification-over-regression
how-can-we-use-an-unlabelled-datasetwithout-having-a-target-column-in-supervised-learning-algorithms
is-it-possible-to-test-the-probability-of-improving-the-model-accuracy-without-using-cross-validation-if-yes-please-explain.
what-cross-validation-technique-would-you-use-on-a-time-series-data-set.
how-can-you-create-a-model-with-a-very-unbalanced-dataset-for-example-working-with-credit-card-fraud-data-and-there-are-very-few-real-fraud-cases-while-the-majority-of-the-cases-are-non-fraudulent.
smote-techniques-to-balance-datasets
neural-networks-1
briefly-explain-how-a-basic-neural-network-works
activation-functions
what-is-the-role-of-the-activation-function
why-tanh-activation-function-preferred-over-sigmoid
why-is-the-relu-activation-function-is-better-than-the-sigmoid-activation-function
what-is-the-use-of-the-leaky-relu-function
what-is-the-dying-relu-problem-in-neural-networks
why-is-rectified-linear-unit-a-good-activation-function
what-is-the-activation-function-why-do-we-need-them
what-is-backward-and-forward-propagation
what-is-backpropagation-in-neural-networks-in-a-pure-mathematical-sense
cost-function
backpropagation-1
difference-between-convex-and-non-convex-cost-function-what-does-it-mean-when-a-cost-function-is-non-convex
convolutional-neural-networks
what-is-cnn-how-does-cnn-work
what-are-convolution-layers
recurrent-neural-networks
long-short-term-memory-networks
weight-initialization
how-are-weights-initialized-in-a-network
batch-vs.-stochastic-gradient-descent
hyper-parameters
learning-rate
what-is-deep-learning
what-is-gradient-descent-how-does-it-work
stochastic-gradient-descent
gradient-descent-stuck-in-local-minima-and-misses-true-minima.
stochastic-vs.-gradient-descent
what-is-the-difference-between-model-parameters-and-hyperparameters
what-do-you-mean-by-dropout-and-batch-normalization
what-is-vanishing-gradient-descent
what-is-exploding-gradient-descent
what-is-lstm-and-bilstm
explain-gates-used-in-lstm-with-their-functions.
what-is-the-difference-between-lstm-and-gru
what-is-padding
what-are-pooling-and-flattening
what-is-epoch-batch-and-iteration-in-deep-learning
what-is-an-auto-encoder
what-do-you-understand-by-boltzmann-machine-and-restricted-boltzmann-machines
explain-generative-adversarial-network.
what-is-adam-whats-the-main-difference-between-adam-and-sgd
when-would-you-use-adam-and-when-sgd
neural-network-how-do-they-learn
neural-network-during-learning-phase
gradient-descent-1
back-propagation
softmax-function
what-happens-if-the-learning-rate-is-set-too-high-or-too-low
sql
